{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Measuring Systems\n",
    "\n",
    "Many terms floating around:\n",
    "\n",
    "- Instrumentation\n",
    "- Monitoring\n",
    "- Log analysis\n",
    "- Observability\n",
    "- High Cardinality\n",
    "- Tracing\n",
    "\n",
    "What does it mean? And why would I care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Observability is Property of a System\n",
    "\n",
    "... just like:\n",
    "\n",
    "* Usability -- The user can find his/her way around the front end\n",
    "* Efficiency -- The application does not waste system resources\n",
    "* Maintainability -- A Software Engineer can find his/her way around the source code\n",
    "* Testability -- A Software Engineer could write effective tests for the system (if he wanted)\n",
    "* Debugability -- An SRE/SE can understand pathological behavior (Related: [Cantrill (2018)](https://www.slideshare.net/bcantrill/debugging-under-fire-keeping-your-head-when-systems-have-lost-their-mind))\n",
    "\n",
    "> Observability -- The operator can understand the internal state of a system while it's running\n",
    "\n",
    "We all want observable applications. Otherwise we would not be here.\n",
    "\n",
    "<hr/>\n",
    "Source: https://www.xaprb.com/slides/devopsdc-what-is-observability  \n",
    "Source: https://en.wikipedia.org/wiki/Observability  \n",
    "Source: https://thenewstack.io/monitoring-and-observability-whats-the-difference-and-why-does-it-matter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Sources for Observability\n",
    "\n",
    "Provided by the Application:\n",
    "* Logs\n",
    "* Status endpoints (`/stats.json`, `/proc`)\n",
    "* Instrumentation (`StatsD.gauge('Base.queued', 12)`, Zipkin)\n",
    "\n",
    "Provided by the Runtime:\n",
    "* JMX, PyMX\n",
    "* Debuggers (gdb, jdb, pdb)\n",
    "* Profilers\n",
    "\n",
    "Provided by the Kernel:\n",
    "* Dynamic tracing (DTrace, eBPF) \n",
    "* System profilers (perf)\n",
    "* Network sniffing (pcap)\n",
    "\n",
    "Provided by Hardware:\n",
    "* PCM/MSR registers (Intel)\n",
    "* SMART disk interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Common Denominator: Events\n",
    "\n",
    "All the above data sources can be regarded as emitting events:\n",
    "\n",
    "```\n",
    "{ event=\"HTTP_START\", reqid=2398721, endpoint=\"/\", srcip=\"10.8.20.132\", t=1535120313.123 }\n",
    "{ event=\"HTTP_END\", reqid=2398721, status=\"OK\", bytes=125232, t=1535120313.123  }\n",
    "{ event=\"HTTP\", endpoint=\"/\", duration[ms]=1.23, status=\"200\", srcip=\"10.8.20.132\", t=1535120313.123 }\n",
    "{ event=\"funccall\", name=\"Customer.payment\", args=[120, \"USD\"], t=1535120313.123 }\n",
    "{ event=\"cpu_idle\", value=1231522, unit=jiffy, t=1535120313 }\n",
    "{ event=\"syscall\", name=\"read\", pid=1231, duration[us]=18.1, t=1535120313.123123152 }\n",
    "{ event=\"shedule_on_cpu\", pid=1231 , t=1535120313.123123152 }\n",
    "{ event=\"shedule_off_cpu\", pid=1231, t=1535120313.123123152 }\n",
    "```\n",
    "\n",
    "<!--\n",
    "\n",
    "Remarks:\n",
    "- Events seem to be used as a term for state changes.\n",
    "- Some of the data sources are not attached to state changes, e.g. \"disk free %\", but more to the state the system is in. We can introduce measurement \"events\", to make that fit our description here.\n",
    "- Events as K-V pairs is relatively arbitrary.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Geometric View on Events\n",
    "\n",
    "Events are points in a high dimensional space:\n",
    "\n",
    "- Each attribute name gives an axes.\n",
    "- Each attribute value, determines the location on that axes.\n",
    "- Attribues that are not set are set to a special value `undef`.\n",
    "\n",
    "![](../img/events.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Challenges\n",
    "\n",
    "- High Dimensionality: Lots of axes\n",
    "- High Cardinality: Lots of values on a single discrete axes (userid, pid)\n",
    "- High Volume: Lots of events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Coping Strategies\n",
    "\n",
    "* Select event sources (reduce dimensionality, volume)  \n",
    "  E.g. only look at log data\n",
    "\n",
    "* Select/Forget attributes (reduce dimensionality)  \n",
    "  E.g. only look at (duration, url, host)\n",
    "\n",
    "* Filter attribute value (reduce dimensionality, volume)  \n",
    "  E.g. only record events with user_id=25\n",
    "\n",
    "* Sample Events (reduce volume)  \n",
    "  E.g. only record every 100s HTTP request.\n",
    "\n",
    "* Group values (reduce cardinality)  \n",
    "  E.g. ip => ip range (192.*)\n",
    "\n",
    "* Aggregate events (reduce volume)  \n",
    "  over time (within this minute) and across dimensions (e.g. users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Models\n",
    "\n",
    "(1) Documents (e.g. JSON)\n",
    "- Events are naturally expressed as JSON documents\n",
    "- Used by Log aggregators, APM tools: ELK (ElasticSearch/Lucene), Splunk, Honeycomb, Dynatrace ([Cassandra](https://www.dynatrace.com/platform/dynatrace-architecture/))\n",
    "\n",
    "(2) Tables (Relational Data)\n",
    "- Pre-selection of attributes allows to impose table structure\n",
    "- Used by some APM tools: NewRelic ([MySQL](http://highscalability.com/blog/2011/7/18/new-relic-architecture-collecting-20-billion-metrics-a-day.html)), VividCortext ([MySQL](http://highscalability.com/blog/2015/3/30/how-we-scale-vividcortexs-backend-systems.html))\n",
    "\n",
    "(3) Metrics / Time Series (TSDB)\n",
    "- Focus a single attribute over time\n",
    "- Like two column table (TIME, ATTRIBUTE)\n",
    "- Discrete time axes (10s, 60s) typical\n",
    "- Continues value axes (float) typical\n",
    "- Used by Monitoring systems, APM tools: Graphite, Prometheues, Influx, Circonus/IRONdb, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tradeoff\n",
    "\n",
    "* Documents/Tables: are full/high \"fidelity\" but relatively expensive at full capture.\n",
    "\n",
    "* Metrics are compact, aggregated, efficient, but canâ€™t be disaggregated.\n",
    "\n",
    "Source: https://www.xaprb.com/slides/devopsdc-what-is-observability/#9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log volume per day: 259 MB\n"
     ]
    }
   ],
   "source": [
    "# Numeric Example: Storage Volume Logs vs. Metrics\n",
    "\n",
    "# Access logs\n",
    "req_per_second = 3\n",
    "log_lines_per_req = 1\n",
    "bytes_per_log_line = 1000\n",
    "seconds_per_day = 24*60*60\n",
    "bytes_per_kb = 1000\n",
    "bytes_per_mb = 1000 * bytes_per_kb\n",
    "log_mb_per_day = bytes_per_log_line * log_lines_per_req * req_per_second * seconds_per_day / bytes_per_mb\n",
    "print(\"Log volume per day: {:,.0f} MB\".format(log_mb_per_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric volume per day: 0.057600 Mb\n"
     ]
    }
   ],
   "source": [
    "# Metric Storage: request-rate, error-rate p50, p95, p99\n",
    "number_of_metrics = 5\n",
    "bytes_per_value = 8\n",
    "aggregation_period_sec = 60\n",
    "values_per_day = number_of_metrics * seconds_per_day / aggregation_period_sec\n",
    "metric_bytes_per_day = bytes_per_value * values_per_day\n",
    "print(\"Metric volume per day: {:.6f} Mb\".format(metric_bytes_per_day/bytes_per_mb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Metrics\n",
    "We say that:\n",
    "\n",
    "> \"Events are rolled-up into metrics.\"\n",
    "\n",
    "It's a three step process:\n",
    "\n",
    "* (1) Select Axes\n",
    "* (2) Group by Time\n",
    "* (3) Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (1) Select Axes\n",
    "   \n",
    "Metric work with a single attribute. All remaining attributes need to be reduced.\n",
    "\n",
    "* Filter attribute (e.g. event=HTTP, host=www1-eu-fra)\n",
    "\n",
    "* Forget attribute (e.g. ignore user_id)\n",
    "\n",
    "Equivalent SQL:\n",
    "\n",
    "```\n",
    "SELECT (t, duration) FROM events WHERE event='HTTP', host='www1-eu-dus';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: Filtering on High Cardinality Axes is Expensive\n",
    "\n",
    "```\n",
    "SELECT (t, duration) FROM events WHERE event='HTTP', user_id=1;\n",
    "SELECT (t, duration) FROM events WHERE event='HTTP', user_id=2;\n",
    "SELECT (t, duration) FROM events WHERE event='HTTP', user_id=3;\n",
    "...\n",
    "SELECT (t, duration) FROM events WHERE event='HTTP', user_id=30231;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Group by Time\n",
    "\n",
    "If you measure time precise enough all events will have different time stamps.\n",
    "\n",
    "Need to group time values into discrete windows. Typical \"periods\" 10s, 60s, 5M.\n",
    "\n",
    "Equivalent SQL:\n",
    "\n",
    "```\n",
    "SELECT (floor(t/period) as T, duration) FROM events WHERE event='HTTP', host='www1-eu-dus';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (3) Aggregate Events\n",
    "\n",
    "All durations in the given time window, need to be summarized to an aggregate.\n",
    "Typical aggregation functions are:\n",
    "\n",
    "* count\n",
    "* mean\n",
    "* sum\n",
    "* min/max\n",
    "* percentile\n",
    "* histogram\n",
    "\n",
    "Equivalent SQL:\n",
    "\n",
    "```\n",
    "SELECT \n",
    "   floor(t/period) as T, \n",
    "   aggregate(duration)\n",
    "FROM events \n",
    "WHERE \n",
    "  event='HTTP', host='www1-eu-dus' \n",
    "GROUP BY\n",
    "  T;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary: Creating Metrics from Events\n",
    "\n",
    "<img src=\"../img/metrics.png\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Higher Rollups\n",
    "\n",
    "So far we were only concerned with rolling-up metrics to a base period of 60s.\n",
    "For graphing, indexing, and long-term storage also rollups on hiher periods are used:\n",
    "\n",
    "<img src=\"../img/rollup.png\" style=\"height:600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics for Engineers\n",
    "\n",
    "What are we doing here today?\n",
    "\n",
    "* Visualizing Events and Metrics\n",
    "* Aggregating Events and Metrics\n",
    "* Modeling and prediction of systems behavior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
